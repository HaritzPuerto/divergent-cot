<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="description"
    content="Fine-Tuning with Divergent Chains of Thought Boosts Reasoning Through Self-Correction in Language Models">
  <meta name="keywords" content="DCoT, Divergent Chain of Thought, CoT">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Divergent Chain of Thought (DCoT)</title>


  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
  <!-- Bootstrap CSS -->
  <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css">

  <style>
    .table td, .table th {
        text-align: center;
    }
    .table td.red-1 {
        background-color: #f8d7da;
    }
    .table td.red-2 {
        background-color: #f5b7b1;
    }
    .table td.red-3 {
        background-color: #f1948a;
    }
    .table td.red-4 {
        background-color: #ec7063;
    }
    .table td.red-5 {
        background-color: #e74c3c;
    }
    .table td.green-1 {
        background-color: #d4edda;
    }
    .table td.green-2 {
        background-color: #a9dfbf;
    }
    .table td.green-3 {
        background-color: #7dcea0;
    }
    .table td.green-4 {
        background-color: #52be80;
    }
    .table td.green-5 {
        background-color: #27ae60;
    }
</style>
</head>

<body>

  <nav class="navbar" role="navigation" aria-label="main navigation">
    <div class="navbar-brand">
      <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
        <span aria-hidden="true"></span>
        <span aria-hidden="true"></span>
        <span aria-hidden="true"></span>
      </a>
    </div>
    <div class="navbar-menu">
      <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
        <a class="navbar-item" href="https://haritzpuerto.github.io">
          <span class="icon">
            <i class="fas fa-home"></i>
          </span>
        </a>

        <div class="navbar-item has-dropdown is-hoverable">
          <a class="navbar-link">
            More Research
          </a>
          <div class="navbar-dropdown">
            <a class="navbar-item" href="https://haritzpuerto.github.io/code-prompting/">
              Code Prompting
            </a>
            <a class="navbar-item" href="https://square.ukp-lab.de">
              SQuARE
            </a>
          </div>
        </div>
      </div>

    </div>
  </nav>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Fine-Tuning with Divergent Chains of Thought Boosts Reasoning
              Through Self-Correction in Language Models</h1>
            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <a href="https://haritzpuerto.github.io/">Haritz Puerto</a><sup>1</sup>,</span>
              <span class="author-block">
                Tilek Chubakov<sup></sup>,</span>
              <span class="author-block">
                <a href="https://www.xiaodanzhu.com/">Xiaodan Zhu</a><sup>2</sup>,
              </span>
              <span class="author-block">
                <a href="https://www.harishtayyarmadabushi.com/">Harish Tayyar Madabushi</a><sup>3</sup>,
              </span>
              <span class="author-block">
                <a href="https://www.informatik.tu-darmstadt.de/ukp/ukp_home/head_ukp/index.en.jsp">Iryna
                  Gurevych</a><sup>1</sup>
              </span>
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block"><sup>1</sup>UKP Lab, Technical University of Darmstadt, Hessian.AI</span>
              <span class="author-block"><sup>2</sup>Queen's University</span>
              <span class="author-block"><sup>3</sup>University of Bath</span>
            </div>

            <div class="column has-text-centered">
              <div class="publication-links">
                <!-- PDF Link. -->
                <span class="link-block">
                  <a href="https://arxiv.org/pdf/2011.12948" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                    </span>
                    <span>Paper</span>
                  </a>
                </span>
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2011.12948" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="ai ai-arxiv"></i>
                    </span>
                    <span>arXiv</span>
                  </a>
                </span>
                <!-- Code Link. -->
                <span class="link-block">
                  <a href="https://github.com/HaritzPuerto/DCoT"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>
                <!-- Models Link. -->
                <span class="link-block">
                  <a href="https://huggingface.co/collections/haritzpuerto/dcot-667ade6bb3c1b9aac8267b71"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">ðŸ¤—
                    </span>
                    <span> Models</span>
                  </a>
                </span>
                <!-- Dataset Link. -->
                <span class="link-block">
                  <a href="https://figshare.com/s/995e234cdfa5092749ab"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="far fa-images"></i>
                    </span>
                    <span>Data</span>
                  </a>
                </span>
              </div>

            </div>
          </div>
        </div>
      </div>
    </div>
  </section>



  <section class="section">
    <div class="container is-max-desktop">
      <!-- Abstract. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <b>TLDR:</b> Divergent Chain of Thought (DCoT) consists of requiring models to generate multiple CoTs before choosing an answer. Adding DCoT data to instruction tuning allows models to improve performance through self-correction.
        </div>
      </div>
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            <p>
              We present a novel method of further improving performance by requiring models to compare multiple
              reasoning chains before generating a solution in a single inference step. We call this method Divergent
              CoT (DCoT).
            </p>
            <p>
              We generate a DCoT dataset where a question is answered by a series of alternative (and correct) chains of
              thought.
              Importantly, all these CoTs are part of the same label, thus, forcing the LLM to learn how to generate
              multiple CoTs in a single inference step.
            </p>
            <p>
              We find that instruction tuning on DCoT datasets boosts the performance of LLMs of all sizes (from 1.3B to
              70B).
              These performance gains stem from models generating multiple divergent reasoning chains in a single
              inference step, indicative of the enabling of
              self-correction in language models.
            </p>
          </div>
        </div>
      </div>
      <!--/ Abstract. -->

      <!-- Intro Image -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3"></h2>
          <div class="">
            <img src="./static/images/intro.png" class="" alt="Intro" />
          </div>
        </div>
      </div>
      <!--/ Intro Image. -->
    </div>
  </section>


  <section class="section">
    <div class="container is-max-desktop">
      <!-- Method -->

      <div class="columns is-centered">
        <div class="column is-full-width">
          <h2 class="title is-3">Methods</h2>
          <div class="content has-text-centered">
            <img src="./static/images/method.png" class="" alt="Method" />
          </div>
        </div>
      </div>

      <div class="columns is-centered">
        <div class="column is-full-width">
          <h2 class="title is-4">Diverse Chain of Thought (DCoT)</h2>
          <div class="content has-text-justified">
            <p>
              We instruction-tune LLMs to generate a sequence of divergent CoTs before selecting the final answer in a single inference step at inference time. To this end, we devise a DCoT instruction template, where we introduce a set of commands (in brackets) to request the number of CoTs to generate:
              </p>
            <!-- create centered text block -->
            <div class="content has-text-centered">
              <p>
                <b>Prompt:</b>[Question] Question [Options] Options [Number of answers] k</br>
                <b>Response:</b>[Answer 1] CoT_1 [Answer 2] ... [Answer k] CoT_k [Final answer] answer
              </p>
            </div>
          </div> 

          <h2 class="title is-4">Chain of Thought (CoT) Baseline</h2>
          <div class="content has-text-justified">
            <p>
              Similarly, to establish a comparable baseline, we instruction-tune the same LLMs using the more traditional CoT format.
              To ensure a fair comparison, we use the same reasoning chains for training.
              As shown in the figure above, each data point is composed of a question and a CoT, and a question may appear in more than one data point but with a different CoT. 
              In this way, the model leverages CoT diversity at training time but, unlike in <b>DCoT</b>, it does not do so at inference time.
            </p>
          </div>           

        </div>
      </div>
      <!--/ Method -->

      <!-- Data Generation -->
      <div class="columns is-centered">
        <div class="column is-full-width">
          <h2 class="title is-3">CoT Data Generation</h2>
          <div class="content has-text-justified">
            <p>
              We use GPT 3.5 turbo in the zero-shot setting with multiple triggers, such as <em>Let's think step by step</em> to generate CoTs.
              For each question, we select four random CoT triggers.
              We limit the number of CoTs to four to ensure that the targets fit the context window of the LLMs.
            </p>
          </div>
        </div>
      </div>
      <!--/ Data Generation -->

      <!-- Results -->
      <div class="columns is-centered">
        <div class="column is-full-width">
          <h2 class="title is-3">Results</h2>
          <div class="content has-text-justified">
            <p>
              <table class="table table-striped table-hover">
                <thead>
                  <tr>
                    <th>Method</th>
                    <th>Phi 1.5 (1.3B)</th>
                    <th>Phi 2 (2.7B)</th>
                    <th>LLaMA 7B</th>
                    <th>LLaMA 13B</th>
                    <th>LLaMA 70B</th>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td><b>DCoT</b></td>
                    <td>49.39</td>
                    <td>62.60</td>
                    <td>60.80</td>
                    <td>66.18</td>
                    <td>68.63</td>
                  </tr>
                  <tr>
                    <td>CoT</td>
                    <td>47.20</td>
                    <td>60.85</td>
                    <td>58.97</td>
                    <td>64.39</td>
                    <td>66.96</td>
                  </tr>
                </tbody>
              </table>
              
            </p>

            <p>
              The table shows the average results of DCoT and CoT across 8 QA reasoning tasks.
              We observe that DCoT achieves consistent and significant performance gains compared to CoT across all LLM families and sizes.
            </p>

            <p>The datasets are:
              <table><thead>
                <tr>
                  <th>Dataset</th>
                  <th>Reasoning Type</th>
                </tr></thead>
              <tbody>
                <tr>
                  <td>ARC</td>
                  <td>High-School Science</td>
                </tr>
                <tr>
                  <td>BGQA</td>
                  <td>Logic</td>
                </tr>
                <tr>
                  <td>CoinFlip</td>
                  <td>State-tracking</td>
                </tr>
                <tr>
                  <td>ConditionalQA</td>
                  <td>Conditional</td>
                </tr>
                <tr>
                  <td>GSM8K</td>
                  <td>Math</td>
                </tr>
                <tr>
                  <td>HotpotQA</td>
                  <td>Explicit multli-hop</td>
                </tr>
                <tr>
                  <td>LCC</td>
                  <td>Symbolic</td>
                </tr>
                <tr>
                  <td>Quartz</td>
                  <td>Qualitative relationships</td>
                </tr>
                <tr>
                  <td>StrategyQA</td>
                  <td>Implicit multi-hop</td>
                </tr>
              </tbody>
              </table>


            </p>
          </div>
        </div>
      </div>

      <!--/ Self-Correction -->
      <div class="columns is-centered">
        <div class="column is-full-width">
          <h2 class="title is-3">Self-Correction (DCoT@2 - DCoT@1)</h2>
          <p>
            The table below shows the performance gain by genrating 2 CoTs (i.e, DCoT@2 - DCoT@1).
            We observe performance gains by simply generating a second CoT in over 62% of cases (i.e., 25 out of 40 LLM x Dataset) and larger than 0.5 for more than half of the datasets for Phi 1.5, Phi2, LLaMA2 13B, and 70B.
          </p>
          <div class="content has-text-justified">
            <p>
              <div class="table-responsive">
                <table class="table table-hover">
                    <thead class="thead">
                        <tr>
                            <th>LLM</th>
                            <th>ARC</th>
                            <th>BGQA</th>
                            <th>CQA</th>
                            <th>GSM8K</th>
                            <th>HQA</th>
                            <th>LLC</th>
                            <th>Quartz</th>
                            <th>StrQA</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>Phi 1.5</td>
                            <td class="green-1">1.26</td>
                            <td class="green-2">2.1</td>
                            <td class="green-1">0.1</td>
                            <td class="green-3">3</td>
                            <td class="green-1">0.83</td>
                            <td class="red-5">-14</td>
                            <td class="green-3">3.38</td>
                            <td class="green-1">1.11</td>
                        </tr>
                        <tr>
                            <td>Phi 2</td>
                            <td class="red-3">-3.56</td>
                            <td class="red-2">-2.38</td>
                            <td class="green-1">0.95</td>
                            <td class="green-1">0.8</td>
                            <td class="green-1">1.06</td>
                            <td class="green-5">14</td>
                            <td class="green-2">1.55</td>
                            <td class="red-1">-0.85</td>
                        </tr>
                        <tr>
                            <td>LLama2 7B</td>
                            <td class="green-1">1.28</td>
                            <td class="red-1">-0.99</td>
                            <td class="red-1">-0.56</td>
                            <td class="green-4">4</td>
                            <td class="red-1">-0.01</td>
                            <td class="green-4">6</td>
                            <td class="red-1">-1.04</td>
                            <td class="green-1">0.25</td>
                        </tr>
                        <tr>
                            <td>LLama2 13B</td>
                            <td class="green-4">4.15</td>
                            <td class="green-1">0.91</td>
                            <td class="red-1">-1.02</td>
                            <td class="green-3">3</td>
                            <td class="green-1">2.02</td>
                            <td class="green-5">12</td>
                            <td class="green-1">0.77</td>
                            <td class="red-2">-2.03</td>
                        </tr>
                        <tr>
                            <td>LLama2 70B</td>
                            <td class="green-3">3.24</td>
                            <td class="green-2">1.38</td>
                            <td class="green-3">3.68</td>
                            <td class="green-5">10</td>
                            <td class="green-1">0</td>
                            <td class="green-4">4</td>
                            <td class="red-1">-1</td>
                            <td class="red-4">-4.07</td>
                        </tr>
                    </tbody>
                </table>
              </div>
                
            </p>

            
            <p>
              These results indicate that DCoT tuning enables models to self-correct. <br>
              It is important to note that our training data includes only reasoning chains that lead to the correct answer, never incorrect ones. This suggests that the ability to self-correct can be enabled in LLMs without explicitly training for it. <br>
              We argue that this self-correct ability stem from the model's attempt to generate subsequent correct CoTs. In other words, the model may generate a first wrong CoT without knowing it, but it generates a second CoT that is correct and, therefore, as a side-effect, corrects the first one.
            </p>
          </div>
        </div>
      </div>



     
    </div>
  </section>


  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@misc{puerto2024dcot,
                        title={Fine-Tuning with Divergent Chains of Thought Boosts Reasoning Through Self-Correction in Language Models}, 
                        author={Haritz Puerto and Tilek Chubakov and Xiaodan Zhu and Harish Tayyar Madabushi and Iryna Gurevych},
                        year={2024},
                        eprint={2407.03181},
                        archivePrefix={arXiv},
                        primaryClass={cs.CL},
                        url={https://arxiv.org/abs/2407.03181}, 
                      }
      </code></pre>
    </div>
  </section>


  <footer class="footer">
    <div class="container">
      <div class="content has-text-centered">
        <a class="icon-link" href="./static/videos/nerfies_paper.pdf">
          <i class="fas fa-file-pdf"></i>
        </a>
        <a class="icon-link" href="https://github.com/HaritzPuerto/DCoT" class="external-link" disabled>
          <i class="fab fa-github"></i>
        </a>
      </div>
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">
            <p>This website is based on <a href="https://nerfies.github.io">Nerfies</a>
              and licensed under a <a rel="license"
                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
                Commons Attribution-ShareAlike 4.0 International License</a>.
            </p>
            
          </div>
        </div>
      </div>
    </div>
  </footer>

  <script src="https://code.jquery.com/jquery-3.5.1.slim.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@popperjs/core@2.5.2/dist/umd/popper.min.js"></script>
  <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js"></script>

</body>

</html>